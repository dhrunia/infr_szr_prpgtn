{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%reset -f\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import lib.io.stan\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'datasets/id001_ac'\n",
    "fit_data_dir = 'jureca/data'\n",
    "results_dir = 'results/exp10/exp10.7/exp10.7.2'\n",
    "os.makedirs(results_dir,exist_ok=True)\n",
    "os.makedirs(f'{results_dir}/logs',exist_ok=True)\n",
    "os.makedirs(f'{results_dir}/figures',exist_ok=True)\n",
    "\n",
    "network = np.load(f'{data_dir}/AC_network.npz')\n",
    "SC = network['SC']\n",
    "K = np.max(SC)\n",
    "SC = SC / K\n",
    "SC[np.diag_indices(SC.shape[0])] = 0\n",
    "gain_mat = network['gain_mat']\n",
    "\n",
    "mdld_data = np.load(f'{data_dir}/AC_fit_trgt.npz')['fit_trgt']\n",
    "mdld_data_ds = mdld_data[0:-1:20,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = SC.shape[0]\n",
    "ns = gain_mat.shape[0]\n",
    "nt = mdld_data_ds.shape[0]\n",
    "I1 = 3.1\n",
    "tau0 = 2857.0\n",
    "# epsilon = 0.1\n",
    "\n",
    "# stan_fname = 'vep-snsrfit-cntr'\n",
    "# lib.io.stan.create_process(['bash','/home/anirudhnihalani/scripts/stancompile.sh', stan_fname],block=True)\n",
    "\n",
    "# x0_star = np.zeros(nn)\n",
    "# x_init = -2.0*np.ones(nn)\n",
    "# z_init = 3.5*np.ones(nn)\n",
    "# amplitude = 0.1*np.ones(ns)\n",
    "# offset = 180*np.ones(ns)\n",
    "# epsilon = 0.01\n",
    "\n",
    "# param_init = {'x0_star':x0_star, 'x_init':x_init, 'z_init':z_init, 'amplitude':amplitude,\n",
    "#                 'offset':offset, 'epsilon':0.1}\n",
    "# param_init_file = 'param_init.R'\n",
    "# lib.io.stan.rdump(f'{results_dir}/Rfiles/param_init.R',param_init)\n",
    "\n",
    "for sigma in np.arange(0.01, 0.51, 0.01):\n",
    "    for epsilon in np.arange(0.01, 0.51, 0.01):\n",
    "        data = {'nn':nn, 'ns':ns, 'nt':nt, 'I1':I1, 'tau0':tau0, 'SC':SC, \n",
    "                'K':K, 'gain': gain_mat, 'sigma':sigma, 'epsilon':epsilon, 'slp':mdld_data_ds}\n",
    "        input_Rfile = f'fit_data_sigma{sigma:0.2f}_eps{epsilon:0.2f}.R'\n",
    "        os.makedirs(fit_data_dir,exist_ok=True)\n",
    "        lib.io.stan.rdump(f'{fit_data_dir}/{input_Rfile}',data)\n",
    "    #     nchains = 4\n",
    "    #     with open('vep-snsrfit-cntr.sh','r') as fd:\n",
    "    #         slurm_script = fd.read().format(f'{results_dir}/Rfiles', results_dir, input_Rfile, nchains, eps)\n",
    "    #     with open(f'tmp/vep-snsrfit-cntr-sigma{sigma:0.5f}.sh','w') as fd:\n",
    "    #         fd.write(slurm_script)\n",
    "    #     lib.io.stan.create_process(['sbatch',f'tmp/vep-snsrfit-ode-sigma{sigma:0.5f}_eps{epsilon:0.5f}.sh'],block=False)\n",
    "    \n",
    "# sigma = 0.1\n",
    "# data = {'nn':nn, 'ns':ns, 'nt':nt, 'I1':I1, 'tau0':tau0, 'gain':gain_mat, 'SC':SC, \\\n",
    "#         'K':K, 'sigma':sigma, 'epsilon':epsilon, 'slp':mdld_data_ds}\n",
    "# input_Rfile = f'fit_data_sigma{sigma:0.5f}_eps{epsilon:0.5f}.R'\n",
    "# os.makedirs(f'{results_dir}/Rfiles',exist_ok=True)\n",
    "# lib.io.stan.rdump(f'{results_dir}/Rfiles/{input_Rfile}', data)\n",
    "\n",
    "# cmd = f'./vep-snsrfit-cntr sample save_warmup=1 num_warmup=200 num_samples=200 adapt delta=0.8 algorithm=hmc engine=nuts \\\n",
    "# max_depth=10 stepsize_jitter=1.0 data file={results_dir}/Rfiles/{input_Rfile} \\\n",
    "# output file={results_dir}/samples_sigma{sigma:0.5f}_eps{epsilon:0.5f}.csv refresh=5'\n",
    "# print(cmd.split(' '))\n",
    "# lib.io.stan.create_process(cmd.split(' '), block=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lib.io.stan\n",
    "import importlib\n",
    "importlib.reload(lib.io.stan)\n",
    "\n",
    "csv_fname = 'results/exp10/exp10.7/exp10.7.2/samples_sigma0.01_eps0.01_chain1.csv'\n",
    "nwarmup = 500\n",
    "nsampling = 300\n",
    "variables_of_interest = ['lp__','accept_stat__','stepsize__','treedepth__','n_leapfrog__',\\\n",
    "                         'divergent__', 'energy__','x0',  'x', 'z', 'amplitude', 'offset',\\\n",
    "                         'x_init', 'z_init', 'time_step']\n",
    "pstr_samples_1 = lib.io.stan.read_samples(csv_fname,nwarmup,nsampling) # read sampler diagnostics and x0 for all sampling iterations\n",
    "\n",
    "# csv_fname = 'results/exp10/exp10.4/samples_eps0.1_chain1.csv'\n",
    "# nwarmup = 1000\n",
    "# nsampling = 1000\n",
    "# ignore_warmup = True\n",
    "# variables_of_interest = ['x','z']\n",
    "# pstr_samples_2 = lib.io.stan.read_samples(csv_fname,nwarmup,nsampling,ignore_warmup,variables_of_interest) # read 10 samples of hidden state variables x and z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import lib.plots.stan\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.subplot(211)\n",
    "plt.violinplot(pstr_samples_1['x0']);\n",
    "plt.axhline(-2.0,color='red')\n",
    "xtick_labels = []\n",
    "for i in range(84):\n",
    "    if(i%2 == 0):\n",
    "        xtick_labels.append(str(i+1))\n",
    "    else:\n",
    "        xtick_labels.append('')\n",
    "plt.xticks(np.r_[1:85],xtick_labels);\n",
    "plt.xlabel('Region#',fontsize=15);\n",
    "plt.ylabel('$x_0$',fontsize=15);\n",
    "\n",
    "lib.plots.stan.nuts_diagnostics(pstr_samples_1)\n",
    "\n",
    "# # Mean and 2*std of source activity(x) estimated from posterior samples\n",
    "# plt.figure(figsize=(15,20))\n",
    "# x_mean = np.mean(pstr_samples_1['x'], axis = 0)\n",
    "# x_std = np.std(pstr_samples_1['x'], axis = 0)\n",
    "# nt = x_mean.shape[0]\n",
    "# nn = x_mean.shape[1]\n",
    "# for i in range(nn):\n",
    "#     plt.plot(x_mean[:,i]+4*i)\n",
    "#     plt.fill_between(np.r_[0:nt], x_mean[:,i] - 2*x_std[:,i] + 4*i, x_mean[:,i] + 2*x_std[:,i] + 4*i,alpha=0.1)\n",
    "# plt.title('source activity(x)',fontsize=15);\n",
    "# plt.xlabel('time',fontsize=15);\n",
    "# plt.ylabel('Region#',fontsize=15);\n",
    "# plt.yticks(np.mean(x_mean,axis=0) + 4*np.r_[0:nn], np.r_[1:nn+1]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntwrk = np.load('datasets/id001_ac/AC_network.npz')\n",
    "gain = ntwrk['gain_mat']\n",
    "src_sig = pstr_samples_1['x']\n",
    "amplitude = pstr_samples_1['amplitude']\n",
    "offset = pstr_samples_1['offset']\n",
    "slp = np.zeros([src_sig.shape[0],src_sig.shape[1],gain.shape[0]])\n",
    "for i,sample in enumerate(src_sig):\n",
    "#     seeg[i] = amplitude[i,:] * ((gain @ sample.T).T + offset[i,:]);\n",
    "    slp[i] = amplitude[i] * (np.log(gain @ np.exp(sample).T).T + offset[i])\n",
    "    \n",
    "\n",
    "mdld_data = np.load('datasets/id001_ac/AC_fit_trgt.npz')\n",
    "plt.figure(figsize=(15,4))\n",
    "plt.plot(mdld_data_ds,'k',alpha=0.4);\n",
    "plt.plot(slp[-1],'r', alpha=0.4);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ez = [59]\n",
    "pz = [74, 82]\n",
    "plt.figure(figsize=(15,10))\n",
    "ax_src_x = plt.subplot(211)\n",
    "ax_src_z = plt.subplot(212)\n",
    "sample_idx = -1\n",
    "for i in range(84):\n",
    "    if i in ez: \n",
    "        ax_src_x.plot(pstr_samples_1['x'][sample_idx,:,i], color='red');\n",
    "        ax_src_z.plot(pstr_samples_1['z'][sample_idx,:,i], color='red');\n",
    "    elif i in pz:\n",
    "        ax_src_x.plot(pstr_samples_1['x'][sample_idx,:,i], color='orange');\n",
    "        ax_src_z.plot(pstr_samples_1['z'][sample_idx,:,i], color='orange');\n",
    "    else:\n",
    "        ax_src_x.plot(pstr_samples_1['x'][sample_idx,:,i], color='black', alpha=0.1);\n",
    "        ax_src_z.plot(pstr_samples_1['z'][sample_idx,:,i], color='black', alpha=0.1);\n",
    "ax_src_x.set_title(\"Source activity - x\")\n",
    "ax_src_z.set_title(\"Source activity - z\")\n",
    "\n",
    "plt.figure()\n",
    "for i in range(84):\n",
    "    if i in ez: \n",
    "        plt.plot(pstr_samples_1['x'][-1,:,i], pstr_samples_1['z'][-1,:,i], color='red')\n",
    "    elif i in pz:\n",
    "        plt.plot(pstr_samples_1['x'][-1,:,i], pstr_samples_1['z'][-1,:,i], color='orange')\n",
    "#     else:\n",
    "#         plt.plot(pstr_samples_1['x'][-1,:,i], pstr_samples_1['z'][-1,:,i], color='black')\n",
    "plt.xlabel('x', fontsize=12.0)\n",
    "plt.ylabel('z', fontsize=12.0)\n",
    "plt.title('Phase Space')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,4))\n",
    "plt.subplot(151)\n",
    "plt.hist(pstr_samples_1['amplitude'][500:].flatten())\n",
    "plt.title('Amplitude')\n",
    "plt.subplot(152)\n",
    "plt.hist(pstr_samples_1['offset'][500:].flatten())\n",
    "plt.title('Offset')\n",
    "plt.subplot(153)\n",
    "plt.plot(pstr_samples_1['time_step'][500:])\n",
    "plt.title('time_step')\n",
    "plt.subplot(154)\n",
    "plt.hist(pstr_samples_1['x_init'][500:].flatten())\n",
    "plt.title('x_init')\n",
    "plt.subplot(155)\n",
    "plt.hist(pstr_samples_1['z_init'][500:].flatten())\n",
    "plt.title('z_init')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
