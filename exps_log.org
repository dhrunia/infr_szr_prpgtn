#+STARTUP: latexpreview
* Experiment 1:
Test how the number of sensors affects the inference by setting up sources and sensors
in a 2D space.
*Outputs*: results/exp1
*Report*: Experiment discarded: There is an error in code.The value for K (connectivity scaling) 
should be -ve. But +ve value was used. Need to rerun the experiment with -ve value of K.
* Experiment 2:
Date: /02-02-2018/
Generate a propagation pattern in a network with 5 nodes where node 2 is EZ and node 5 is PZ
*Outputs*: results/exp3
*Report*: I was using +ve values for K (connecitivity scaling) which should have been -ve. Using
-ve values for K generated the required propagation patterns.
* Experiment 3:
/Date: 02-02-2018/
Fit a network of 2D epileptors with 5 nodes using source signals (/x/ and /z/) as modelled data
*Outputs*: results/exp2
*Report*: Out of 8 chains 5 have converged. Of these 5 chains 4 have inferred the x0 accurately 
even distinguishing between EZ and PZ. However, 1 chain inferred wrongly an extra node as EZ 
apart from the actual EZ and PZ.

* Experiment 4:
Date: /02-02-2018/
Rerun Exp.1 with the correct values for K (see Exp.2)
*Outputs*: results/exp4
*Report*: $\hat r$ did not decrease as the #of sensors used for inference are increased.

* Experiment 5:
/Date: 05-02-2018/
Continuing from Exp.3, Check if increasing sigma would allow all chains to converge.
*Outputs*: results/exp5
*Report*: All the chains have converged with higher sigma. However, one chains still inferred
a different mode than the true one.

* Experimet 6:
/Date: 06-02-2018/
Now that Exp.3 and 5 showed promising results for inference at source level. Try fitting 
at sensor level with a simple source sensor geometry like in Exp. 1 (or 4) inferring only x0
*Outputs*: results/exp6
*Report*: Different chains have converged to different modes, only one chain explored the mode
of interest. 
Why isn't each chain exploring all the modes? 
None of the chains are reporting divergence, for most of the chains rhat is ~1 and tree depth
is below the max. depth, So it is not the case that sampler is stuck in some complicated
curvature of posterior.
It looks like sampler is getting stuck in the artificial maxima created due to the logarithm scale
in which the sampler operates.
** Experimet 6.1:
Date: 15-02-18
- In Exp. 6 x0s are not constrained with any lower or upper bound. This is causing stable nodes
x0 values to be inferred with very low values even -10, which in turn is causing strong inhibition
on other nodes due to coupling.
- Since in Exp. 6 different chains are converging to different modes and not exploring other
modes, increase the epsilon(observation noise) to see if sampler manages to jump between modes.
- Use non-centered parameterization for all inferred parameters as it is considered to produce
posteriors with simpler geomtries
*outputs*: results/exp6.1
*Report*: Most of the chains reported divergence, with espilon=0.2 delta=0.9 and x0 lower bound of -3.0
Could the divergence be due to the lower bound on x0? Because in exp.6 when using unconstrained and centered version
of x0 only a couple of the chains reported divergence
** Experiment 6.2:
/Date: 19-02-18/
- Check if using unconstrained(no lower or upperbound) non-centered version of x0s would stop the chains to diverge
*outputs*: results/exp6.2
*Report*: Yes, using unconstrained x0s none of the chains reported divergent transitions. But still different chains
are converging to different modes and no chain is exploring all modes.
** Experiment 6.3:
/Date: 19-02-18/
Check if running Exp 6.2 with more sampling iterations(5000) would allow the sampler to explore other modes
in each chain
** Experiment 6.4:
/Date:20-02-18/
Looks like the log posterior is creating artificial maxima by exaggerating the differences between two values with
very low probabilities, and then getting stuck in these maxima. Check 1) if inferring the source signals along with
the x0s would improve the convergence 2) initialize the sampler hidden states(x) to the inferred signal from exp 7.
* Experiment 7:
/Date:13-02-2018/
Infer the source signals from the seeg data without even using the dynamical model.
*Outputs*: results/exp7
*Report*: The sampler is able to infer the source signals but the variance at each time point
is very high. The signal obtained by taking the mean of inferred signals and then computing
there moving average matches well with the true source signals.
** Experiment 7.1:
Check if this simple model would be able to infer the source signals with data generated from
TVB using a realistic SC and gain matrices
*Code*: TVB_forward_sim.ipynb, vep-src-infer.ipynb
*Outputs*: results/exp7.1
*Report*: Yes, HMC sampler is able to infer the source signals quite accurately for synthetic SEEG data generated using 
6D epileptor(TVB). However, it is able to do so only for very low eps (variance in observation model). Particularly,
for eps=0.001 the sampler has finished 500 warmup + 500 sampling in around 12 hours. For eps>0.009 the sampler is stuck
in the warmup for a week.

* Experiment 8:
/Date:22-02-18/
As evident from exp. 7 sampler posterior is simpler to explore when hidden states are also inferred.
Check how inference works with toy network model in exp. 6 but this time infer also the source signals
*Output*: results/exp8
*Report*: Even with source signals inferred the posterior is still difficult to explore. Increasing the 
sigma made the sampler explore the posterior better, but too high a sigma would not constrain source signals
to follow epileptor dynamics and too low a sigma would make the posterior to difficult to explore. 
A manual parameter sweep starting from high values of sigma and lowering it in each next run showed that 
at sigma = 0.1 the posterior is simple enough to explore while following epileptor dynamics.
